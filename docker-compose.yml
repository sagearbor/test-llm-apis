services:
  llm-test:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: llm-test-app

    # Port mapping
    ports:
      - "3003:3003"

    # Environment variables from .env file
    env_file:
      - .env

    # Volume mounts for persistent data
    volumes:
      # Runtime data (usage tracking, rate limits) - MUST persist across restarts
      - ./src/data:/app/src/data
      # Logs directory (optional)
      - ./logs:/app/logs

    # Restart policy
    restart: unless-stopped

    # Health check
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3003/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s

    # Resource limits (adjust as needed)
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
